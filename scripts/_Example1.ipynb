{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Taller Keras $-$ Ejemplo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential, load_model, save_model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from pandas import DataFrame\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from plotmatrix import pretty_plot_confusion_matrix, PlotMatrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción a las Redes Neuronales (NNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Objetivos:__\n",
    "* Implementar una NN de varias capas en Keras para clasificar la base de datos MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar la interfaz a la base de datos que viene con Keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# lectura de los datos\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "print('Raw data shapes:')\n",
    "print('X train:', train_images.shape, 'Y train:', train_labels.shape)\n",
    "print('X test:', test_images.shape, 'Y test:', test_labels.shape)\n",
    "\n",
    "# pre-procesamiento de los datos\n",
    "train_images = train_images.reshape((60000, -1))\n",
    "train_images = train_images.astype('float32') / 255.\n",
    "\n",
    "test_images = test_images.reshape((10000, -1))\n",
    "test_images = test_images.astype('float32') / 255.\n",
    "\n",
    "# one-hot encoding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels  = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Modified data shapes:')\n",
    "print('X train:', train_images.shape, 'Y train:', train_labels.shape)\n",
    "print('X test:', test_images.shape, 'Y test:', test_labels.shape)\n",
    "\n",
    "data_shape = train_images.shape[1:]\n",
    "\n",
    "print('')\n",
    "print('data shape:', data_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red neuronal multicapa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](nn2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ejercicio:__ Diseñe una red neuronal con 4 capas ocultas, más una capa de salida (como en la figura). Las capas deben ser densas. El número de neuronas en las capas debe ser: 512, 512, 256, 128, y 10 en la capa de salida.\n",
    "\n",
    "Use funciones de activación ReLU (excepto en la capa de salida, donde se usará softmax). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejemplo de cómo definir una arquitectura sin usar \"Sequential\"\n",
    "\n",
    "def NNmulticapa(input_shape):\n",
    "    I = Input(shape=input_shape, name='input')\n",
    "    X = Dense(16, activation='relu', name='dense1')(I)\n",
    "    X = Dense(10, activation='relu', name='classifier')(X)\n",
    "    model = Model(I, X, name='NN-multicapa')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'network2' in globals(): del network2\n",
    "network2 = None\n",
    "\n",
    "network2 = NNmulticapa(data_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ejercicio:__ Compile y entrene la red neuronal de 2 capas.\n",
    "\n",
    "Utilice el optimizador 'RMSprop', usted elige el learning rate apropiado. Use la función de pérdida 'categorical_crossentropy', y use como métrica el 'accuracy'.\n",
    "\n",
    "Para el entrenamiento, use 15 épocas (iteraciones), un tamaño de batch de 64 ó 128, y haga una partición de validación de 0.16666 (5/6)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1e-4\n",
    "opt = optimizers.RMSprop(lr=alpha)\n",
    "\n",
    "network2.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time()\n",
    "history2 = network2.fit(x=train_images, y=train_labels, epochs=20, batch_size=128, validation_split=0.1666)\n",
    "toc = time()\n",
    "print('total training time:', toc-tic, 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ver el historial de desempeño de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history2.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history2.history['accuracy']\n",
    "val_acc = history2.history['val_accuracy']\n",
    "loss = history2.history['loss']\n",
    "val_loss = history2.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc)+1)\n",
    "\n",
    "# figure\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs, acc, 'ro', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results2 = network2.evaluate(test_images, test_labels)\n",
    "#print('results loss:', results2[0])\n",
    "#print('results accuracy:', results2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute predictions (inference process)\n",
    "predictions2 = network2.predict(test_images)\n",
    "\n",
    "# from predictions compute most probable class\n",
    "pred2 = np.argmax(predictions2, 1)\n",
    "test_labs = np.argmax(test_labels, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_labs, pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM2 = confusion_matrix(test_labs, pred2)\n",
    "\n",
    "# plot confusion matrix\n",
    "cf2 = DataFrame(CM2)\n",
    "pretty_plot_confusion_matrix(cf2, annot=True, pred_val_axis='x', figsize=(10,10), fz=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second plot\n",
    "PlotMatrix(CM2, figsize=(10,10), cmap=plt.cm.Blues, title='Confusion Matrix', fz=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Implementar una arquitectura de red multicapa con 2 capas intermedias (más la capa clasificadora).\n",
    "\n",
    "* Usar las funciones de activación que usted desee. En la capa clasificadora, usar 'softmax'.\n",
    "\n",
    "* Elegir los parámetros a su discreción: optimizador, tamaño de paso (*learning rate*), número de épocas, ...\n",
    "\n",
    "* Mostrar los resultados del desempeño en entrenamiento y prueba. El objetivo es diseñar una red que tenga un mejor desempeño que la de la clase pasasa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Con la red del ejercicio anterior, experimentar usando diferentes clasificadores, para encontrar aquel que mejora el desempeño de su red.\n",
    "\n",
    "* Experimente cambiando también otros parámetros: alpha, número de epochs, batch_size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Implementar una arquitectura de red multicapa con 4 capas intermedias (más la capa clasificadora).\n",
    "\n",
    "* Usar las funciones de activación que usted desee. En la capa clasificadora, usar 'softmax'.\n",
    "\n",
    "* Elegir los parámetros a su discreción: optimizador, tamaño de paso (*learning rate*), número de épocas, ...\n",
    "\n",
    "* Mostrar los resultados del desempeño en entrenamiento y prueba. El objetivo es diseñar una red que tenga un mejor desempeño que el Ejercicio 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
